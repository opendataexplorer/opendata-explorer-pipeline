{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import getsize\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'data/output'\n",
    "filters_path = \"data/filters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "files_under_5mb = []\n",
    "files_under_5mb_size = []\n",
    "for file in files:\n",
    "    sizes.append(getsize(f\"{output_path}/{file}\"))\n",
    "    if getsize(f\"{output_path}/{file}\") < 5000000:\n",
    "        files_under_5mb.append(file)\n",
    "        files_under_5mb_size.append(getsize(f\"{output_path}/{file}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Size: {sum(sizes)/1000000000} GB\")\n",
    "print(f\"Count: {len(files_under_5mb)}\")\n",
    "print(f\"Files under 5mb Total Size: {sum(files_under_5mb_size)/1000000000} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter(file):\n",
    "    default_checked = {\"geo\": \"Canada\", \"uom\": \"Tonnes\", \"type_of_structure\": \"Total residential\", \"type_of_work\": \"Types of work, total\"}\n",
    "    col_names = {\"geo\": \"Geography\", \"uom\": \"Unit of Measurement\"}\n",
    "    ignore_cols = [\"ref_date\", \"dguid\", \"uom_id\", \"scalar_factor\", \"scalar_id\", \"vector\", \"coordinate\", \"value\", \"symbol\", \"terminated\", \"decimals\", \"status\"]\n",
    "    unique_filter_list = []\n",
    "    \n",
    "    dt = pd.read_json(f\"data/output/{file}\")\n",
    "\n",
    "    for col in dt.columns:\n",
    "        try: \n",
    "\n",
    "            if col not in ignore_cols:\n",
    "\n",
    "                filter_list = []\n",
    "                for row in dt[col]:\n",
    "                    filter_list.append(row)\n",
    "                unique_filter = np.unique(filter_list).tolist()\n",
    "                unique_filter_dict = []\n",
    "\n",
    "                for value in unique_filter:\n",
    "                    for index, (col_checked, filter_checked) in enumerate(default_checked.items()):\n",
    "                        if col == col_checked and value == filter_checked:\n",
    "                            unique_filter_dict.append({\"name\": value, \"filter\":True})\n",
    "                        elif {\"name\": value, \"filter\":False} not in unique_filter_dict and {\"name\": value, \"filter\":True} not in unique_filter_dict:\n",
    "                            unique_filter_dict.append({\"name\": value, \"filter\":False})\n",
    "\n",
    "\n",
    "\n",
    "                if len([item for item in unique_filter_dict if item['filter'] == True]) == 0:\n",
    "                    for index, value in enumerate(unique_filter_dict):\n",
    "                        if index == 0:\n",
    "                            value['filter'] = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                for index, (col_original, name) in enumerate(col_names.items()):\n",
    "                    if col == col_original:\n",
    "                        friendly_name = name\n",
    "                        break;\n",
    "                    else:\n",
    "                        friendly_name = str.replace(col.title(), \"_\", \" \")\n",
    "\n",
    "                if col == 'geo':\n",
    "                    pivot_value = True\n",
    "                else:\n",
    "                    pivot_value = False\n",
    "\n",
    "                unique_filter_list.append({\"col\": col, \"name\": friendly_name, \"pivot\": pivot_value, \"filters\": unique_filter_dict})\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    with open(f'data/filters/{Path(file).stem}-filters.json', 'w') as f:\n",
    "        json.dump(unique_filter_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(files_under_5mb):\n",
    "    create_filter(file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d03ffd2fe1fc33624d3d101d41fe53b9a889f205653b5be6699976b1038969e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
